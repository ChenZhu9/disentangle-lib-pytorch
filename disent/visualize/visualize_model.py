# coding=utf-8
# Copyright 2018 The DisentanglementLib Authors.  All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# ========================================================================
#
# ADAPTED FROM Google's disentanglement_lib:
# https://github.com/google-research/disentanglement_lib
#
# (Major) Modifications for pytorch and disent by Nathan Michlo

"""
Visualization module for disentangled representations.
"""

import numbers
import os
from disent.dataset.util.io import ensure_dir_exists
from disent.visualize import visualize_util
from disent.visualize.util import (get_dataset, plt_images_grid, plt_images_minimal_square, reconstructions_to_images)
from disent.util import to_numpy
import numpy as np
import torch




# ========================================================================= #
# Visualise varying single factor for model                                 #
# ========================================================================= #


def latent_traversal_1d_multi_dim(
        decoder_fn,
        latent_vector,
        dimensions=None,
        values=None
):
    """Creates latent traversals for a latent vector along multiple dimensions.

    Creates a 2d grid image where each grid image is generated by passing a
    modified version of latent_vector to the generator_fn. In each column, a
    fixed dimension of latent_vector is modified. In each row, the value in the
    modified dimension is replaced by a fixed value.

    Args:
      decoder_fn: Function that computes (fixed size) images from latent
        representation. It should accept a single Numpy array argument of the same
        shape as latent_vector and return a Numpy array of images where the first
        dimension corresponds to the different vectors in latent_vectors.
      latent_vector: 1d Numpy array with the base latent vector to be used.
      dimensions: 1d Numpy array with the indices of the dimensions that should be
        modified. If an integer is passed, the dimensions 0, 1, ...,
        (dimensions - 1) are modified. If None is passed, all dimensions of
        latent_vector are modified.
      values: 1d Numpy array with the latent space values that should be used for
        modifications. If an integer is passed, a linear grid between -1 and 1
        with that many points is constructed. If None is passed, a default grid is
        used (whose specific design is not guaranteed).
      transpose: Boolean which indicates whether rows and columns of the 2d grid
        should be transposed.

    Returns:
      2d list of images that are outputs from the traversal.
    """
    # TODO: EXTRACT
    # Make sure everything is a numpy array
    latent_vector = to_numpy(latent_vector)

    # Defualt values
    if dimensions is None:
        dimensions = latent_vector.shape[0]  # Default case, use all available dimensions.
    if values is None:
        values = 11  # Default case, get 11 evenly spaced samples per factor

    # Handle integers instead of arrays
    if isinstance(dimensions, numbers.Integral):
        assert dimensions <= latent_vector.shape[0], "The number of dimensions of latent_vector is less than the number of dimensions requested in the arguments."
        assert dimensions >= 1, "The number of dimensions has to be at least 1."
        dimensions = np.arange(dimensions)
    if isinstance(values, numbers.Integral):
        assert values > 1, "If an int is passed for values, it has to be >1."
        values = np.linspace(-1., 1., num=values)

    # Make sure everything is a numpy array
    dimensions = to_numpy(dimensions)
    values = to_numpy(values)

    assert latent_vector.ndim == 1, "Latent vector needs to be 1-dimensional."
    assert dimensions.ndim == 1, "Dimensions vector needs to be 1-dimensional."
    assert values.ndim == 1, "Values vector needs to be 1-dimensional."

    # We iteratively generate the rows/columns for each dimension as different
    # Numpy arrays. We do not preallocate a single final Numpy array as this code
    # is not performance critical and as it reduces code complexity.
    factor_images = []
    for dimension in dimensions:
        # Creates num_values copy of the latent_vector along the first axis.
        latent_traversal_vectors = np.tile(latent_vector, [len(values), 1])
        # Intervenes in the latent space.
        latent_traversal_vectors[:, dimension] = values
        # Generate the batch of images
        # TODO: cuda wont always be correct
        latent_traversal_vectors = torch.as_tensor(latent_traversal_vectors).cuda()
        images = decoder_fn(latent_traversal_vectors)
        images = reconstructions_to_images(images)
        factor_images.append(images)

    return to_numpy(factor_images)


# ========================================================================= #
# Visualise Random Latent Samples                                           #
# ========================================================================= #


# ORIG
# def plt_sampled_latent_space(system, num_samples=16, figsize_ratio=0.75):
#     z = torch.randn(num_samples, system.model.z_size).cuda()
#     images = system.model.decode(z)
#     images = reconstructions_to_images(images)
#     plt_images_minimal_square(images, figsize_ratio=0.75)

def latent_random_samples(decoder_fn, z_size, num_samples=16):
    # TODO: cuda wont always be correct
    z = torch.randn(num_samples, z_size).cuda()
    images = decoder_fn(z)
    images = reconstructions_to_images(images)
    return to_numpy(images)

def plt_latent_random_samples(decoder_fn, z_size, num_samples=16, figsize_ratio=0.75):
    images = latent_random_samples(decoder_fn, z_size, num_samples)
    plt_images_minimal_square(images, figsize_ratio=figsize_ratio)


# ========================================================================= #
# Visualise Latent Traversals                                               #
# ========================================================================= #


# ORIG
# def plt_traverse_latent_space(system, num_samples=16, values=11, dimensions=None, figsize_ratio=0.75):
#     obs = torch.stack(system.dataset_train.sample_observations(num_samples)).cuda()
#     z_mean, z_logvar = system.model.encode_gaussian(obs)
#     for z_idx in range(num_samples):
#         images = latent_traversal_1d_multi_dim(system.model.decode, z_mean[z_idx, :], dimensions=dimensions, values=values)
#         plt_images_grid(images, figsize_ratio=figsize_ratio)

def latent_traversals(z_mean, decoder_fn, dimensions=None, values=None):
    # for each sample
    traversals = []
    for i in range(len(z_mean)):
        # TODO: add support for cycle methods from below? Is that actually useful?
        grid = latent_traversal_1d_multi_dim(decoder_fn, z_mean[i, :], dimensions=dimensions, values=values)
        traversals.append(grid)
    # return
    return to_numpy(traversals)

def plt_traverse_latent_space(z_mean, decoder_fn, dimensions=None, values=None, figsize_ratio=0.75):
    traversals = latent_traversals(z_mean, decoder_fn, dimensions=dimensions, values=values)
    for images_grid in traversals:
        plt_images_grid(images_grid, figsize_ratio=figsize_ratio)


# ========================================================================= #
# Visualise Latent Cycles (for animations)                                  #
# ========================================================================= #


def _z_std_gaussian_cycle(base_z, z_means, z_logvars, z_idx, num_frames):
    # Cycle through quantiles of a standard Gaussian.
    zs = np.repeat(np.expand_dims(base_z, 0), num_frames, axis=0)
    zs[:, z_idx] = visualize_util.cycle_gaussian(base_z[z_idx], num_frames, loc=0, scale=1)
    return zs

def _z_fitted_gaussian_cycle(base_z, z_means, z_logvars, z_idx, num_frames):
    # Cycle through quantiles of a fitted Gaussian.
    zs = np.repeat(np.expand_dims(base_z, 0), num_frames, axis=0)
    loc = np.mean(z_means[:, z_idx])
    total_variance = np.mean(np.exp(z_logvars[:, z_idx])) + np.var(z_means[:, z_idx])
    zs[:, z_idx] = visualize_util.cycle_gaussian(base_z[z_idx], num_frames, loc=loc, scale=np.sqrt(total_variance))
    return zs

def _z_fixed_interval_cycle(base_z, z_means, z_logvars, z_idx, num_frames):
    # Cycle through [-2, 2] interval.
    zs = np.repeat(np.expand_dims(base_z, 0), num_frames, axis=0)
    zs[:, z_idx] = visualize_util.cycle_interval(base_z[z_idx], num_frames, -2., 2.)
    return zs

def _z_conf_interval_cycle(base_z, z_means, z_logvars, z_idx, num_frames):
    # Cycle linearly through +-2 std dev of a fitted Gaussian.
    zs = np.repeat(np.expand_dims(base_z, 0), num_frames, axis=0)
    loc = np.mean(z_means[:, z_idx])
    total_variance = np.mean(np.exp(z_logvars[:, z_idx])) + np.var(z_means[:, z_idx])
    scale = np.sqrt(total_variance)
    zs[:, z_idx] = visualize_util.cycle_interval(base_z[z_idx], num_frames, loc - 2. * scale, loc + 2. * scale)
    return zs

def _z_minmax_interval_cycle(base_z, z_means, z_logvars, z_idx, num_frames):
    # Cycle linearly through minmax of a fitted Gaussian.
    zs = np.repeat(np.expand_dims(base_z, 0), num_frames, axis=0)
    zs[:, z_idx] = visualize_util.cycle_interval(base_z[z_idx], num_frames, np.min(z_means[:, z_idx]), np.max(z_means[:, z_idx]))
    return zs

LATENT_CYCLE_MODES = {
    'std_gaussian_cycle': _z_std_gaussian_cycle,
    'fitted_gaussian_cycle': _z_fitted_gaussian_cycle,
    'fixed_interval_cycle': _z_fixed_interval_cycle,
    'conf_interval_cycle': _z_conf_interval_cycle,
    'minmax_interval_cycle': _z_minmax_interval_cycle,
}

def latent_cycle(decoder_func, z_means, z_logvars, mode='fixed_interval_cycle', num_animations=4, num_frames=20):
    # convert
    z_means, z_logvars = to_numpy(z_means), to_numpy(z_logvars)
    # get mode
    z_gen_func = LATENT_CYCLE_MODES[mode]
    animations = []
    for i, base_z in enumerate(z_means[:num_animations]):
        frames = []
        for j in range(base_z.shape[0]):
            z = z_gen_func(base_z, z_means, z_logvars, j, num_frames)
            z = torch.as_tensor(z).cuda()  # TODO: wont always be cuda
            frames.append(reconstructions_to_images(decoder_func(z)))
        animations.append(frames)
    return to_numpy(animations)


# ========================================================================= #
# Visualise Reconstructions                                                 #
# ========================================================================= #


# ORIG
# def _save_reconstructions():
#     # Save reconstructions.
#     real_pics = dataset.sample_observations(num_images)
#     raw_pics = f(dict(images=real_pics), signature="reconstructions", as_dict=True)["images"]
#     pics = activation(raw_pics)
#     paired_pics = np.concatenate((real_pics, pics), axis=2)
#     paired_pics = [paired_pics[i, :, :, :] for i in range(paired_pics.shape[0])]
#     results_dir = ensure_dir_exists(output_dir, "reconstructions")
#     visualize_util.grid_save_images(paired_pics, os.path.join(results_dir, "reconstructions.jpg"))

def sample_observations_and_reconstruct(gaussian_encoder_fn, decoder_fn, dataset, num_samples=16):
    obs = torch.stack(dataset.sample_observations(num_samples)).cuda()
    # reconstruct
    z_mean, z_logvar = gaussian_encoder_fn(obs)
    x_recon = decoder_fn(z_mean)
    # get images
    obs, x_recon = reconstructions_to_images(obs), reconstructions_to_images(x_recon)
    return to_numpy(obs), to_numpy(x_recon)

def plt_sample_observations_and_reconstruct(gaussian_encoder_fn, decoder_fn, dataset, num_samples=16, figsize_ratio=0.75):
    obs, x_recon = sample_observations_and_reconstruct(gaussian_encoder_fn, decoder_fn, dataset, num_samples=num_samples)
    plt_images_minimal_square(obs, figsize_ratio=figsize_ratio)
    plt_images_minimal_square(x_recon, figsize_ratio=figsize_ratio)


# ========================================================================= #
# Visualise Latent Traversals                                               #
# ========================================================================= #


def save_model_visualisations(
        gaussian_encoder_fn, decoder_fn, dataset, z_size,
        output_dir,
        overwrite=False,
        num_images=64,
        num_animations=5,
        num_frames=20,
        fps=10
):
    """Takes trained model from model_dir and visualizes it in output_dir.

    Args:
      model_dir: Path to directory where the trained model is saved.
      output_dir: Path to output directory.
      overwrite: Boolean indicating whether to overwrite output directory.
      num_animations: Integer with number of distinct animations to create.
      num_frames: Integer with number of frames in each animation.
      fps: Integer with frame rate for the animation.
      num_points_irs: Number of points to be used for the IRS plots.
    """
    # Create the output directory if necessary.
    if os.path.isdir(output_dir):
        if overwrite:
            print(f'[WARNING] Directory Exists... DELETING: {output_dir}')
            import shutil
            shutil.rmtree(output_dir)
        else:
            raise ValueError("Directory already exists and overwrite is False.")

    # convert string to dataset if needed
    dataset = get_dataset(dataset)

    # TODO: get activation function | add support throughout disent
    # activation = dict(logits=sigmoid, tanh=tanh)['logits']

    # sample random observations & feed forward | used for visualisations
    obs = torch.stack(dataset.sample_observations(num_images)).cuda()  # TODO: cuda wont always be right
    z_means, z_logvars = gaussian_encoder_fn(obs)
    x_recons = decoder_fn(z_means)

    # Save reconstructions.
    results_dir = ensure_dir_exists(output_dir, "reconstructions")
    visualize_util.minimal_square_save_images(reconstructions_to_images(obs), os.path.join(results_dir, "reconstructions_input.jpg"))
    visualize_util.minimal_square_save_images(reconstructions_to_images(x_recons), os.path.join(results_dir, "reconstructions_output.jpg"))
    visualize_util.minimal_square_save_images(np.concatenate([reconstructions_to_images(obs), reconstructions_to_images(x_recons)], axis=2), os.path.join(results_dir, "reconstructions.jpg"))

    # Save samples.
    results_dir = ensure_dir_exists(output_dir, "sampled")
    images = latent_random_samples(decoder_fn, z_size, num_images)
    visualize_util.minimal_square_save_images(images, os.path.join(results_dir, "samples.jpg"))

    # Save latent traversals.
    results_dir = ensure_dir_exists(output_dir, "traversals")
    traversals = latent_traversals(z_means, decoder_fn)
    for i, image_grid in enumerate(traversals):
        visualize_util.grid_save_images(image_grid, os.path.join(results_dir, f"traversals_{i}.jpg"))

    # Save the latent traversal animations.
    results_dir = ensure_dir_exists(output_dir, "animated_traversals")
    for mode in LATENT_CYCLE_MODES:
        animations = latent_cycle(decoder_fn, z_means, z_logvars, num_animations=num_animations, mode=mode)
        animations = reconstructions_to_images(animations, mode='int', moveaxis=False)  # axis already moved above
        for i, animation in enumerate(animations):
            visualize_util.save_grid_animation(animation, os.path.join(results_dir, f"{mode}_{i}.gif"), fps=fps)

    # TODO: Interventional effects visualization.
    # from disent.visualize.visualize_irs import vis_all_interventional_effects
    # factors = data.sample_factors(num_points_irs)
    # obs = data.sample_observations_from_factors(factors)
    # latents = f(dict(images=obs), signature="gaussian_encoder", as_dict=True)["mean"]
    # results_dir = os.path.join(output_dir, "interventional_effects")
    # vis_all_interventional_effects(factors, latents, results_dir)


# ========================================================================= #
# END                                                                       #
# ========================================================================= #


if __name__ == '__main__':

    # MAKE SYSTEM
    def make_system(load_path, loss='ada-gvae', dataset='dsprites', model='simple-fc', z_size=6) -> 'VaeSystem':
        from disent.systems.vae import VaeSystem
        from disent.util import load_model
        system = VaeSystem(dataset_train=dataset, model=model, loss=loss, hparams=dict(lr=0.001, num_workers=8, batch_size=64, z_size=z_size))
        system = load_model(system, load_path, cuda=True)
        return system

    # CELL
    system = make_system(loss='beta-vae', dataset='3dshapes', model='simple-fc', load_path='data/trained-e1-3dshapes-simple-fc.ckpt')

    save_model_visualisations(
        system.model.encode_gaussian,
        system.model.decode,
        system.dataset_train,
        system.model.z_size,
        output_dir='data/output/model',
        overwrite=True,
        num_images=16,
        num_animations=5,
        num_frames=30,
        fps=10,
    )

    # get observations
    # obs = torch.stack(system.dataset_train.sample_observations(16))
    # z_mean, z_logvar = system.model.encode_gaussian(obs.cuda())
    # z_mean = to_numpy(z_mean)
    #
    # for z_idx in range(z_mean.shape[1]):
    #     images = latent_traversal_1d_multi_dim(system.model.decode, z_mean[z_idx, :], None)
    #     util.plt_images_grid(images)
    #     plt.show()
    #     # visualize_util.grid_save_images([pics], os.path.join(results_dir, f"traversals_{z_idx}.jpg"))
