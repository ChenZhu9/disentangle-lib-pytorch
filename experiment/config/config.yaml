defaults:
  # system
  - framework: betavae
  - model: vae_conv64
  - optimizer: adam
  - schedule: none
  # data
  - dataset: xyobject
  - dataset_sampling: full_bb
  - augment: none
  # runtime
  - metrics: all
  - run_length: long
  - run_location: cluster_many
  - run_callbacks: vis_slow
  - run_logging: wandb
  # plugins
  - hydra/job_logging: colorlog
  - hydra/hydra_logging: colorlog
  - hydra/launcher: submitit_slurm

job:
  user: '${env:USER}'
  project: 'test-project'
  name: '${framework.name}:${framework.module.recon_loss}|${dataset.name}:${dataset_sampling.name}|${trainer.steps}'
  partition: batch
  seed: NULL

framework:
    beta: 4
    module:
      recon_loss: mse
      loss_reduction: mean_sum

    # only some frameworks support these features
    optional:
      latent_distribution: normal  # only used by VAEs
      overlap_loss: NULL
      usage_ratio: 0.5  # only used by adversarial masked datasets  # pragma: delete-on-release

model:
  z_size: 9

optimizer:
  lr: 1e-3

# CUSTOM DEFAULTS SPECIALIZATION
# - This key is deleted on load and the correct key on the root config is set similar to defaults.
# - Unfortunately this hack needs to exists as hydra does not yet support this kinda of variable interpolation in defaults.
specializations:
  # default samplers -- the framework specified defaults
  dataset_sampler: ${dataset.data_type}_${framework.data_sample_mode}

  # newer samplers -- only active for frameworks that require 3 observations, otherwise random for 2, and exact for 1
  # dataset_sampler: gt_dist_${framework.data_sample_mode}

  # random samplers -- force random sampling of observation pairs or triples
  # dataset_sampler: random_${framework.data_sample_mode}
