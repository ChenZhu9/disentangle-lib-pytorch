defaults:
  # experiment
  - framework: betavae
  - model: conv64alt
  - optimizer: radam
  - dataset: xysquares  # allow framework to override settings here, but placing dataset before framework in defaults
  - augment: none
  - sampling: full_bb
  - metrics: fast
  - schedule: none
  # runtime
  - run_length: long
  - run_location: cluster_many
  - run_callbacks: vis_slow
  - run_logging: wandb
  # plugins
  - hydra/job_logging: colorlog
  - hydra/hydra_logging: colorlog
  - hydra/launcher: submitit_slurm

job:
  user: 'n_michlo'
  project: 'DELETE'
  name: '${framework.name}:${framework.module.recon_loss}|${dataset.name}:${sampling.name}|${trainer.steps}'
  partition: stampede
  seed: NULL

framework:
    beta: 0.003
    module:
      recon_loss: mse4
      loss_reduction: mean
    optional:
      latent_distribution: normal  # only used by VAEs
      overlap_loss: NULL

model:
  z_size: 25

optimizer:
  lr: 5e-4

# CUSTOM DEFAULTS SPECIALIZATION
# - This key is deleted on load and the correct key on the root config is set similar to defaults.
# - Unfortunately this hack needs to exists as hydra does not yet support this kinda of variable interpolation in defaults.
specializations:
  data_wrapper: ${dataset.data_type}_${framework.data_wrap_mode}
#  data_wrapper: gt_dist_${framework.data_wrap_mode}
