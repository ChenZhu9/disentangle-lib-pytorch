# EXPERIMENT 1:
# -m framework=tvae dataset=xysquares
#    framework.module.triplet_scale=1,10,100
#    framework.module.triplet_margin=1,10,100
#    framework.module.detach_decoder=TRUE,FALSE
#    framework.module.detach_no_kl=FALSE
#
# -m framework=tvae dataset=xysquares
#    framework.module.triplet_scale=1,10,100
#    framework.module.triplet_margin=1,10,100
#    framework.module.detach_decoder=TRUE
#    framework.module.detach_no_kl=TRUE

defaults:
  - framework: tvae
  - model: conv64
  - optimizer: radam
  - dataset: xysquares
  - augment: none
  # hydra plugins
  - hydra/job_logging: colorlog
  - hydra/hydra_logging: colorlog
  - hydra/launcher: submitit_slurm

# ------------------ #
# EXPERIMENT OPTIONS #
# ------------------ #

# remember to set timeout limits below
trainer:
  epochs: 28800  # not resilient to change in dataset size, we rather limit by steps (len(dataset) / batch_size)
  steps: 28800
  cuda: TRUE
  prepare_data_per_node: TRUE

model:
  z_size: 9
  y_size: 9

dataset:
  num_workers: 8
  batch_size: 256
  data_dir: '/tmp/${env:USER}/datasets'
  try_in_memory: FALSE
  gpu_augment: FALSE
  # varying factors (if applicable for pairs) -- sample in range: [min, max]
  k: [0, -1]
  k_radius: [0, -1]
  # varying factors (if applicable for triplets) -- sample in range: [min, max]
  n_k: [0, -1]
  n_k_mode: 'bounded_below'
  n_k_radius: [0, -1]
  n_k_radius_mode: 'bounded_below'

optimizer:
  lr: 1e-3

# --------------- #
# RUNTIME OPTIONS #
# --------------- #

logging:
  logs_dir: 'logs'
  # logging frequency in number of batchers, default: log_interval=50, save_log_interval=100
  log_interval: 100
  save_log_interval: 200
  # log to online service
  wandb:
    enabled: TRUE
    offline: FALSE
    entity: 'n_michlo'
    project: 'vae-ada-triplet-loss'
    name: '${framework.name}|${model.name}:${model.z_size}|${dataset.name}:${augment.name}'
    group: null
    tags:
      - '${framework.name}'
      - '${dataset.name}'
      - '${optimizer.name}'
      - '${model.name}'

callbacks:
  progress:
    interval: 30
  latent_cycle:
    seed: 7777
    every_n_steps: 600
    mode: 'minmax_interval_cycle'  # 'minmax_interval_cycle', 'fitted_gaussian_cycle'
  metrics:
    every_n_steps: 3600
  correlation:
    repeats_per_factor: 10
    every_n_steps: 7200

hydra:
  job:
    name: 'disent'
  launcher:
    partition: batch
    mem_gb: 0
    timeout_min: 1440  # minutes
    submitit_folder: '${hydra.sweep.dir}/submitit/%j'
  run:
    dir: '${logging.logs_dir}/hydra_run/${now:%Y-%m-%d_%H-%M-%S}_${hydra.job.name}'
  sweep:
    dir: '${logging.logs_dir}/hydra_sweep/${now:%Y-%m-%d_%H-%M-%S}_${hydra.job.name}'
    subdir: '${hydra.job.id}'  # hydra.job.id is not available for dir
