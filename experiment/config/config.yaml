# RUN:
# -m optimizer=adam,radam optimizer.lr=0.0033,0.001,0.00033,0.0001 framework=betavae,adavae dataset=xysquares,cars3d framework.beta=0.1,0.25,1.0,4.0

defaults:
  # experiment
  - framework: betavae
  - model: conv64
  - optimizer: adam
  - dataset: xysquares
  - augment: none
  - sampling: full_bb
  # runtime
  - run_length: short
  - run_location: cluster_many
  - run_callbacks: metrics_slow
  - run_logging: wandb_slow
  # plugins
  - hydra/job_logging: colorlog
  - hydra/hydra_logging: colorlog
  - hydra/launcher: submitit_slurm

job:
  user: 'n_michlo'
  project: 'validate-loss-and-dist-changes'
  name: '${framework.name}:${framework.module.recon_loss}|${dataset.name}:${sampling.name}|${trainer.steps}'
  partition: batch

framework:
    beta: 4  # most VAEs use this
    module:
      recon_loss: mse

model:
  z_size: 9

optimizer:
  lr: 1e-3

# CUSTOM DEFAULTS SPECIALIZATION
# - This key is deleted on load and the correct key on the root config is set similar to defaults.
# - Unfortunately this hack needs to exists as hydra does not yet support this kinda of variable interpolation in defaults.
specializations:
  data_wrapper: ${dataset.data_type}_${framework.data_wrap_mode}
