# @package _global_
trainer:
  epochs: 50400
  steps: 50400
  cuda: TRUE
  prepare_data_per_node: TRUE

dataset:
  num_workers: 8
  batch_size: 256
  data_dir: '/tmp/${env:USER}/datasets'
  try_in_memory: FALSE
  gpu_augment: FALSE