# @package _global_
trainer:
  epochs: 201600
  steps: 201600
  cuda: TRUE
  prepare_data_per_node: TRUE

dataset:
  num_workers: 8
  batch_size: 256
  data_dir: '/tmp/${env:USER}/datasets'
  pin_memory: ${trainer.cuda}
  try_in_memory: FALSE
  gpu_augment: FALSE
