# EXPERIMENT:
# -m framework.loss_adversarial_weight=100.0,10.0 framework.sampler_name=same_k framework.dataset_name=cars3d,smallnorb,shapes3d,dsprites

defaults:
  # runtime
  - run_logging: wandb_fast
  - run_location: griffin
  # plugins
  - hydra/job_logging: colorlog
  - hydra/hydra_logging: colorlog
#  - hydra/launcher: submitit_slurm

trainer:
  cuda: TRUE
  # try increasing the number of steps
  # 15000 takes 40 mins with batch size 512
  steps: 15000

framework:
  # optimizer options
  optimizer_name: 'Adam'
  optimizer_lr: 5e-4
  optimizer_kwargs:
     weight_decay: 1e-6
  # dataset config options
  dataset_name: 'dsprites'  # cars3d, smallnorb, dsprites, shapes3d, xysquares_8x8_mini
  dataset_batch_size: 256  # x3
  dataset_num_workers: ${dataset.num_workers}
  data_root: ${dataset.data_root}
  data_load_into_memory: FALSE  # I don't think this is truly multi-threaded, possible lock on array access?
  # adversarial loss options
  adversarial_mode: 'invert_margin_0.01'  # self, invert, invert_unbounded, invert_margin_0.01
  adversarial_swapped: False
  adversarial_masking: False
  adversarial_top_k: NULL  # NULL or range: [1, batch_size]
  pixel_loss_mode: 'mse'
  # loss extras
  loss_adversarial_weight: 10.0
  loss_out_of_bounds_weight: 100.0   # not really needed
  loss_same_stats_weight: 0.0      # not really needed
  loss_similarity_weight: 1.0      # important
  # sampling config
  sampler_name: 'same_k1_close'   # same_k (might be wrong!), same_k_close, same_k1_close, close_far, close_factor_far_random, close_far_same_factor, same_factor, random_bb, random_swap_manhat, random_swap_manhat_norm
  # model settings
  model_type: 'ae_conv64'
  model_mask_mode: 'none'  # std, diff, none
  # logging settings
  logging_img_scale: FALSE

exp:
  seed: 777
  show_every_n_steps: 300
  rel_save_dir: 'out/adversarial_data_approx/'

job:
  # saving
  save_prefix: ''
  save_model: TRUE
  save_data: TRUE
  name: TEST-${framework.dataset_name}_${framework.adversarial_mode}_aw${framework.loss_adversarial_weight}_${framework.sampler_name}_s${trainer.steps}_${framework.optimizer_name}_lr${framework.optimizer_lr}_wd${framework.optimizer_kwargs.weight_decay}
  # wandb
  user: 'n_michlo'
  project: 'exp-disentangle-dataset-approx'
  partition: stampede
