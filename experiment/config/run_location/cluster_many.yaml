# @package _global_
logging:
  logs_dir: 'logs'

trainer:
  # NULL == auto detect cuda
  # some nodes on the cluster don't have working cuda...
  # revert to CPU so all the jobs don't fail
  cuda: NULL
  prepare_data_per_node: TRUE

dataset:
  num_workers: 8
  batch_size: 256
  data_dir: '/tmp/${env:USER}/datasets'
  pin_memory: ${trainer.cuda}
  try_in_memory: FALSE
  gpu_augment: FALSE

hydra:
  job:
    name: 'disent'
  run:
    dir: '${logging.logs_dir}/hydra_run/${now:%Y-%m-%d_%H-%M-%S}_${hydra.job.name}'
  sweep:
    dir: '${logging.logs_dir}/hydra_sweep/${now:%Y-%m-%d_%H-%M-%S}_${hydra.job.name}'
    subdir: '${hydra.job.id}' # hydra.job.id is not available for dir
  launcher:
    partition: ${job.partition}
    mem_gb: 0
    timeout_min: 1440  # minutes
    submitit_folder: '${hydra.sweep.dir}/submitit/%j'
    array_parallelism: 32
